# -*- coding: utf-8 -*-
"""data Visualizations and preprocessing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16CpyL-_OgQU_hcIyHYDdtolHrADzSki6

CHECK DATASET and LOAD THE DATA
"""

import pandas as pd
import numpy as np

df = pd.read_csv ('/content/churn_ModellingC.csv')

df.head()

df.info()

df.shape

df.tail()

"""# Descriptive Statistics"""

df.describe()

df.describe(include ='all')

df.isnull().sum()

"""ENCODING

# Method 1 (LabelEncoding)
"""

from sklearn.preprocessing import LabelEncoder
from collections import Counter as count

le = LabelEncoder()

df['Geography'].unique()

df['Gegraphy']=le.fit_transform(df['Geography'])

count(df['Geography'])

df

count(df['CreditScore'])

df['CreditScore']=df['CreditScore'].replace(['No','Yes'],[0,1])

count (df['CreditScore'])

"""# method 3 (onehot encoding)"""

df1 = pd.read_csv('/content/Churn_Modelling.csv')

df1['Geography']

Geography = pd.get_dummies(df1['Geography'],prefix= 'Geography_')

Geography

"""# splitting the data (training and testing split)"""

df

df.info()

x=df.iloc[:,0:3]
y=df['CreditScore']

x

y

from sklearn.model_selection import train_test_split

xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3,random_state=11)

xtrain

xtest

from sklearn.preprocessing import StandardScaler,MinMaxScaler

st = StandardScaler()
nm = MinMaxScaler()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

x= np.array([1,2,3,4,5,6])
y= np.power(x,4)

np.power(x,2)

plt.plot(x,y)